{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ced762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2eff1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you have multiple HCS files to process? (yes/no): yes\n",
      "Please enter the path to an HCS file (html/xls/csv) (or 'done' to finish): today2.xlsx\n",
      "Please enter the path to an HCS file (html/xls/csv) (or 'done' to finish): done\n",
      "✅ Successfully processed: today2.xlsx\n",
      "\n",
      "✅ Combined 1 HCS files\n",
      "First few rows of combined data:\n",
      "   ISSTYPE       CARD_NUMBER             CRDH_NAME         ATM_ACCT  \\\n",
      "0  REPLACE  4753960000746392           IJAJ HUSSEN  414701406417018   \n",
      "1  REPLACE  4753960000742094  TEJLAXMI RAJBHANDARI  210200053905015   \n",
      "2  REPLACE  4753960000742102  PURNA BAHADUR KHADGI  210201108720016   \n",
      "3  REPLACE  4753960000742193    SUKRA P. RANJITKAR  210001312381019   \n",
      "4  REPLACE  4753960000742219        BISHNU B SINGH  726105035139015   \n",
      "\n",
      "     ISS_DATE  EXPIR_DATE  CARD_ID  \n",
      "0  2025-03-24  2029-03-24  1308014  \n",
      "1  2025-03-24  2029-03-24  1306670  \n",
      "2  2025-03-24  2029-03-24  1306671  \n",
      "3  2025-03-24  2029-03-24  1306678  \n",
      "4  2025-03-24  2029-03-24  1306680  \n",
      "Would you like to save the combined data to a CSV file? (yes/no): no\n"
     ]
    }
   ],
   "source": [
    "# Update of multiple hcs file\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ask user if they have multiple HCS files\n",
    "multiple_files = input(\"Do you have multiple HCS files to process? (yes/no): \").lower().strip()\n",
    "\n",
    "all_hcs_data = []\n",
    "\n",
    "def process_file(file_path):\n",
    "    \"\"\"Process a single file (CSV, XLS, or HTML) and return a DataFrame.\"\"\"\n",
    "    try:\n",
    "        if file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif file_path.endswith(('.xls', '.xlsx')):\n",
    "            df = pd.read_excel(file_path)\n",
    "        elif file_path.endswith('.html'):\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                html_content = file.read()\n",
    "            df_list = pd.read_html(html_content)\n",
    "            df = df_list[0]\n",
    "            # Set first row as column names for HTML files\n",
    "            df.columns = df.iloc[0]\n",
    "            df = df[1:].reset_index(drop=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Use CSV, XLS/XLSX, or HTML.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if multiple_files == 'yes':\n",
    "    # Ask for multiple file paths\n",
    "    hcs_paths = []\n",
    "    while True:\n",
    "        path = input(\"Please enter the path to an HCS file (html/xls/csv) (or 'done' to finish): \")\n",
    "        if path.lower() == 'done':\n",
    "            break\n",
    "        if os.path.exists(path):\n",
    "            hcs_paths.append(path)\n",
    "        else:\n",
    "            print(\"Error: The file does not exist. Please check the path and try again.\")\n",
    "\n",
    "    if not hcs_paths:\n",
    "        print(\"Error: No valid files provided. Exiting.\")\n",
    "    else:\n",
    "        # Process each HCS file\n",
    "        for hcs_path in hcs_paths:\n",
    "            hcs = process_file(hcs_path)\n",
    "            if hcs is not None:\n",
    "                all_hcs_data.append(hcs)\n",
    "                print(f\"✅ Successfully processed: {hcs_path}\")\n",
    "\n",
    "        # Combine all dataframes\n",
    "        if all_hcs_data:\n",
    "            combined_hcs = pd.concat(all_hcs_data, ignore_index=True)\n",
    "            print(f\"\\n✅ Combined {len(all_hcs_data)} HCS files\")\n",
    "            print(\"First few rows of combined data:\")\n",
    "            print(combined_hcs.head())\n",
    "            # Option to save\n",
    "            save = input(\"Would you like to save the combined data to a CSV file? (yes/no): \").lower().strip()\n",
    "            if save == 'yes':\n",
    "                output_path = input(\"Enter the output file path (e.g., output.csv): \")\n",
    "                combined_hcs.to_csv(output_path, index=False)\n",
    "                print(f\"✅ Saved to {output_path}\")\n",
    "        else:\n",
    "            print(\"No data was successfully processed.\")\n",
    "\n",
    "else:\n",
    "    # Single file processing\n",
    "    hcs_path = input(\"Please enter the path to your HCS file (html/xls/csv): \")\n",
    "    if not os.path.exists(hcs_path):\n",
    "        print(\"Error: The file does not exist. Please check the path and try again.\")\n",
    "    else:\n",
    "        hcs = process_file(hcs_path)\n",
    "        if hcs is not None:\n",
    "            print(f\"\\n✅ Successfully processed: {hcs_path}\")\n",
    "            print(\"First few rows of data:\")\n",
    "            print(hcs.head())\n",
    "            print(f\"Total rows: {len(hcs)}\")\n",
    "            # Option to save\n",
    "            save = input(\"Would you like to save the data to a CSV file? (yes/no): \").lower().strip()\n",
    "            if save == 'yes':\n",
    "                output_path = input(\"Enter the output file path (e.g., output.csv): \")\n",
    "                hcs.to_csv(output_path, index=False)\n",
    "                print(f\"✅ Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "999445f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you have multiple text files for name extraction? (yes/no):  yes\n",
      "Please enter the path to a text file (or 'done' to finish):  today.txt\n",
      "Please enter the path to a text file (or 'done' to finish):  today1.txt\n",
      "Please enter the path to a text file (or 'done' to finish):  today2.txt\n",
      "Please enter the path to a text file (or 'done' to finish):  today3.txt\n",
      "Please enter the path to a text file (or 'done' to finish):  done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully processed: today.txt\n",
      "✅ Successfully processed: today1.txt\n",
      "✅ Successfully processed: today2.txt\n",
      "✅ Successfully processed: today3.txt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you have multiple HCS files to process? (yes/no):  no\n",
      "Please enter the path to your HCS file (html/xls/csv):  hcs.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully processed: hcs.xlsx\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'E_NAME'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'E_NAME'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 139\u001b[0m\n\u001b[1;32m    136\u001b[0m hcs_name_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with actual column name if different\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Normalize names\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m hcs_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m hcs_df[hcs_name_col]\u001b[38;5;241m.\u001b[39mapply(normalize_name)\n\u001b[1;32m    140\u001b[0m extracted_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m extracted_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEXTRACTED_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(normalize_name)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Create matching keys\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'E_NAME'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_name(name):\n",
    "    \"\"\"Normalize a name by converting to uppercase, removing extra spaces, and splitting into components.\"\"\"\n",
    "    if pd.isna(name) or name == \"NaN\":\n",
    "        return {\"first\": \"\", \"middle\": \"\", \"surname\": \"\"}\n",
    "    # Remove extra spaces and convert to uppercase\n",
    "    name = \" \".join(name.split()).upper()\n",
    "    parts = name.split()\n",
    "    \n",
    "    if len(parts) == 1:\n",
    "        return {\"first\": parts[0], \"middle\": \"\", \"surname\": \"\"}\n",
    "    elif len(parts) == 2:\n",
    "        return {\"first\": parts[0], \"middle\": \"\", \"surname\": parts[1]}\n",
    "    else:\n",
    "        return {\"first\": parts[0], \"middle\": \" \".join(parts[1:-1]), \"surname\": parts[-1]}\n",
    "\n",
    "def process_hcs_file(file_path):\n",
    "    \"\"\"Process an HCS file (HTML, CSV, or XLS/XLSX) and return a DataFrame.\"\"\"\n",
    "    try:\n",
    "        if file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif file_path.endswith(('.xls', '.xlsx')):\n",
    "            df = pd.read_excel(file_path)\n",
    "        elif file_path.endswith('.html'):\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                html_content = file.read()\n",
    "            df_list = pd.read_html(html_content)\n",
    "            df = df_list[0]\n",
    "            df.columns = df.iloc[0]\n",
    "            df = df[1:].reset_index(drop=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Use CSV, XLS/XLSX, or HTML.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# --- Process Extracted Names ---\n",
    "multiple_txt_files = input(\"Do you have multiple text files for name extraction? (yes/no): \").lower().strip()\n",
    "all_extracted_names = []\n",
    "\n",
    "if multiple_txt_files == 'yes':\n",
    "    txt_paths = []\n",
    "    while True:\n",
    "        path = input(\"Please enter the path to a text file (or 'done' to finish): \")\n",
    "        if path.lower() == 'done':\n",
    "            break\n",
    "        if os.path.exists(path):\n",
    "            txt_paths.append(path)\n",
    "        else:\n",
    "            print(\"Error: File does not exist. Please check the path and try again.\")\n",
    "\n",
    "    if not txt_paths:\n",
    "        print(\"Error: No valid text files provided. Exiting.\")\n",
    "    else:\n",
    "        for txt_path in txt_paths:\n",
    "            try:\n",
    "                with open(txt_path, 'r', encoding='utf-8') as txt_file:\n",
    "                    for line in txt_file:\n",
    "                        matches = re.findall(r'NPR\\s{0,4}([A-Z][A-Z.\\s]+)', line)\n",
    "                        if matches:\n",
    "                            for match in matches:\n",
    "                                all_extracted_names.append(match.strip())\n",
    "                        else:\n",
    "                            all_extracted_names.append(\"NaN\")\n",
    "                print(f\"✅ Successfully processed: {txt_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error processing {txt_path}: {str(e)}\")\n",
    "else:\n",
    "    txt_path = input(\"Please enter the path to your text file: \")\n",
    "    if not os.path.exists(txt_path):\n",
    "        print(\"Error: File does not exist. Please check the path and try again.\")\n",
    "    else:\n",
    "        try:\n",
    "            with open(txt_path, 'r', encoding='utf-8') as txt_file:\n",
    "                for line in txt_file:\n",
    "                    matches = re.findall(r'NPR\\s{0,4}([A-Z][A-Z.\\s]+)', line)\n",
    "                    if matches:\n",
    "                        for match in matches:\n",
    "                            all_extracted_names.append(match.strip())\n",
    "                    else:\n",
    "                        all_extracted_names.append(\"NaN\")\n",
    "            print(f\"✅ Successfully processed: {txt_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing {txt_path}: {str(e)}\")\n",
    "\n",
    "if not all_extracted_names:\n",
    "    print(\"Error: No names extracted. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "extracted_df = pd.DataFrame({'EXTRACTED_NAME': all_extracted_names})\n",
    "\n",
    "# --- Process HCS Files ---\n",
    "multiple_hcs_files = input(\"Do you have multiple HCS files to process? (yes/no): \").lower().strip()\n",
    "all_hcs_data = []\n",
    "\n",
    "if multiple_hcs_files == 'yes':\n",
    "    hcs_paths = []\n",
    "    while True:\n",
    "        path = input(\"Please enter the path to an HCS file (html/xls/csv) (or 'done' to finish): \")\n",
    "        if path.lower() == 'done':\n",
    "            break\n",
    "        if os.path.exists(path):\n",
    "            hcs_paths.append(path)\n",
    "        else:\n",
    "            print(\"Error: File does not exist. Please check the path and try again.\")\n",
    "\n",
    "    if not hcs_paths:\n",
    "        print(\"Error: No valid HCS files provided. Exiting.\")\n",
    "    else:\n",
    "        for hcs_path in hcs_paths:\n",
    "            hcs = process_hcs_file(hcs_path)\n",
    "            if hcs is not None:\n",
    "                all_hcs_data.append(hcs)\n",
    "                print(f\"✅ Successfully processed: {hcs_path}\")\n",
    "        if all_hcs_data:\n",
    "            hcs_df = pd.concat(all_hcs_data, ignore_index=True)\n",
    "        else:\n",
    "            print(\"Error: No HCS data successfully processed. Exiting.\")\n",
    "            exit()\n",
    "else:\n",
    "    hcs_path = input(\"Please enter the path to your HCS file (html/xls/csv): \")\n",
    "    if not os.path.exists(hcs_path):\n",
    "        print(\"Error: File does not exist. Please check the path and try again.\")\n",
    "    else:\n",
    "        hcs_df = process_hcs_file(hcs_path)\n",
    "        if hcs_df is None:\n",
    "            print(\"Error: HCS file processing failed. Exiting.\")\n",
    "            exit()\n",
    "        print(f\"✅ Successfully processed: {hcs_path}\")\n",
    "\n",
    "# --- Name Matching ---\n",
    "hcs_name_col = 'CRDH_NAME'  # Replace with actual column name if different\n",
    "\n",
    "# Normalize names\n",
    "hcs_df['norm'] = hcs_df[hcs_name_col].apply(normalize_name)\n",
    "extracted_df['norm'] = extracted_df['EXTRACTED_NAME'].apply(normalize_name)\n",
    "\n",
    "# Create matching keys\n",
    "hcs_df['match_key'] = hcs_df['norm'].apply(lambda x: f\"{x['first']}|{x['middle']}|{x['surname']}\")\n",
    "extracted_df['match_key'] = extracted_df['norm'].apply(lambda x: f\"{x['first']}|{x['middle']}|{x['surname']}\")\n",
    "\n",
    "# Use extracted_df as base (smaller set)\n",
    "matched_df = extracted_df.merge(\n",
    "    hcs_df,\n",
    "    how='left',\n",
    "    on='match_key',\n",
    "    suffixes=('_extracted', '_hcs')\n",
    ")\n",
    "\n",
    "# Add extracted name to matched rows\n",
    "matched_df['MATCHED_EXTRACTED_NAME'] = matched_df['EXTRACTED_NAME']\n",
    "\n",
    "# Clean up: keep only necessary columns and remove unmatched rows\n",
    "final_df = matched_df.dropna(subset=[hcs_name_col])  # Drop rows where HCS data wasn't matched\n",
    "final_df = final_df.drop(columns=['norm_extracted', 'norm_hcs', 'match_key'])\n",
    "\n",
    "# Results\n",
    "print(f\"\\nOriginal HCS rows: {len(hcs_df)}\")\n",
    "print(f\"Extracted names: {len(extracted_df)}\")\n",
    "print(f\"Final matched rows: {len(final_df)}\")\n",
    "print(\"\\nFirst few rows of final DataFrame:\")\n",
    "print(final_df.head())\n",
    "\n",
    "# Optionally save to CSV\n",
    "save = input(\"Would you like to save the results to a CSV file? (yes/no): \").lower().strip()\n",
    "if save == 'yes':\n",
    "    output_path = input(\"Enter the output file path (e.g., matched_output.csv): \")\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Results saved to {output_path}\")\n",
    "else:\n",
    "    print(\"Results not saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde3c05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
